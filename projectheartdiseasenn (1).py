# -*- coding: utf-8 -*-
"""ProjectHeartdiseaseNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TucFJSaBLjVznj_2rOz4Dan-CpUJb_4H
"""

#############################################################################################
###################################### Project ##############################################
###Prediction of Heart Disease occurrence based on blood pressure and serum cholesterol levels
##############################################################################################

# Importing all the libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
import pandas_profiling as pp
from tensorflow import keras
from keras.preprocessing import text, sequence
from keras.preprocessing.text import Tokenizer
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import OneHotEncoder 
from sklearn.metrics import mean_squared_error, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report,precision_score

## Mounting the google drive to load the dataset

from google.colab import drive
drive.mount('/content/drive')

"""# Dataset Loading"""

# Loading the dataset

df = pd.read_csv('/content/drive/MyDrive/ML Project/heart.csv')
df.head()

# Taking specfic columns from the dataset
new_df= df[['trestbps','chol','target']].copy()
new_df.head()

"""# Data Normalization """

# Normalize the resting blood pressure and cholesterol level values 

scaler = MinMaxScaler()
new_df[['trestbps', 'chol']] = scaler.fit_transform(new_df[['trestbps', 'chol']])
new_df

# Pairplots are done to understand the relationship between the columns in the dataframe
sns.pairplot(new_df,size=4,vars=['trestbps','chol','target'],kind='scatter',markers=['o','x'])

"""# Data Preprocessing"""

#Preprocessing and dropping null values and duplicates
no_seq = new_df[new_df['trestbps'].isnull()].index
new_df.drop(no_seq, axis=0,inplace=True)
new_df

# Making the columns from the dataframe into arrays - input and output arrays

x = new_df[['trestbps','chol']]
bprest_array = (new_df[['trestbps']]).to_numpy()
chol_array = (new_df[['chol']]).to_numpy()

input_array= np.concatenate((bprest_array,chol_array), axis =1)
output_array = new_df[['target']].to_numpy()

"""# Some Important Functions"""

## Sigmoid activation function
def sigmoid_of(x):
  return 1.0/(1.0+np.exp(-x))


### Derivative of sigmoid function

def sigmoid_derivative_of(y):
  return y*(1-y)

## Mean Square error or loss function
def mean_square_error(predictions, labels):
  N= labels.size
  mse = ((predictions-labels)**2).sum()/(2*N)
  return mse

## Accuracy score function
def accuracy(predictions,labels):
  predictions_correct = predictions.argmax(axis=1) == labels.flatten()
  accuracy = predictions_correct.mean()
  return accuracy 

## Prediction correct classifiers
def correct_preds(predictions,labels):
  predictions_correct = predictions.argmax(axis=1) == labels.flatten()
  correct_preds = np.count_nonzero(predictions_correct, axis=None)
  return correct_preds

"""# Splitting Training and Test data"""

# Using this fucntion to Split training and test data

X_train, X_test, Y_train, Y_test = train_test_split(input_array,output_array, test_size=0.2,random_state=0)

"""# Building Neural network without Regularization Parameter from scratch"""

# Created a class for Neural network without the Regularization parameter
class NN:

  # Defining a constructor
  def __init__(self,X, Y, learningrate,n_input,n_hidden,n_output, iterations):
    self.input = X
    
    self.w_1 = np.random.normal(scale=0.5, size=(n_input,n_hidden)) #(2,2)
    self.w_2 = np.random.normal(scale=0.5,size=(n_hidden,n_output))
    
    self.Y = Y
    self.alpha = learningrate
    self.iterations =iterations
    self.N = Y.size

    # Function for forward propagation and back propagation

  def forwardandbackprop(self):

    results = pd.DataFrame(columns= ["MSE", "Accuracy", "TPR","FPR"])
    for itr in range(self.iterations):
  # feed forward
      hiddenlayer_input = np.dot(self.input,self.w_1)
      hiddenlayer_output = sigmoid_of(hiddenlayer_input)

      outputlayer_input = np.dot(hiddenlayer_output, self.w_2)
      outputlayer_output = sigmoid_of(outputlayer_input)




#backpropagation

      outputlayer_error = outputlayer_output- self.Y
      outputlayer_delta = outputlayer_error * outputlayer_output * (1-outputlayer_output)

      hiddenlayer_error = np.dot(outputlayer_delta,self.w_2.T)
      hiddenlayer_delta = hiddenlayer_error * hiddenlayer_output * (1-hiddenlayer_output)

      mse = mean_square_error(outputlayer_output,self.Y)

      acc = accuracy(outputlayer_output,self.Y)
      cp = correct_preds(outputlayer_output,self.Y)

      y_pr = outputlayer_output.argmax(axis=1)
      y_tr = self.Y.flatten()

      confm =  confusion_matrix(y_tr,y_pr, labels=[0, 1])
      TP = confm[0][0]
      FN = confm[0][1]
      FP = confm[1][0]
      TN = confm[1][1]
      tpr = TP/(TP+FN)
      fpr = FP/(FP+TN)

      results = results.append({"MSE": mse, "Accuracy" : acc, "TPR" : tpr, "FPR": fpr}, ignore_index=True)


# weights update
      
      m = self.input.shape[1]

      w_2_update = (np.dot(hiddenlayer_output.T, outputlayer_delta)) /m
      w_1_update = (np.dot(self.input.T, hiddenlayer_delta))/m

      self.w_2 = self.w_2 - (self.alpha * w_2_update)
      self.w_1 = self.w_1 - (self.alpha * w_1_update)

      

    lst = []
    for i in range(self.iterations):
      lst.append(i+1)
    results['Iteration number'] = np.array(lst)
    columns_titles =['Iteration number', 'MSE','Accuracy','TPR', 'FPR']
    results = results.reindex(columns = columns_titles)
    print(results)
    fig, axes = plt.subplots(1,2, figsize =(15,5))
    results.MSE.plot(ax=axes[0],title="Mean Squared Error")
    results.Accuracy.plot(ax=axes[1],title="Accuracy")
    
    results.plot(x="FPR", y="TPR", ylabel = "TPR",kind="line",title ="ROC curve", color="r", legend=None)
    #sns.scatterplot(data = results, y = "MSE", x = "Iteration number")
    #sns.scatterplot(data = results, y = "Accuracy", x = "Iteration number")
    y_p = outputlayer_output.argmax(axis=1)
    y_t = self.Y.flatten()
    cm = confusion_matrix(y_t,y_p, labels=[0, 1])
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=None)
    disp.plot()
    plt.show()
    meanMSE = results[['MSE']].mean()
    print("Mean Squared Error for " + str(self.iterations)  + " iterations is: \n" + str(meanMSE))
    Acscore= results[['Accuracy']].mean()
    print("Mean Accuracy for " + str(self.iterations)  + " iterations is: \n" + str(Acscore))

    meanTPR = results[['TPR']].mean()
    print("Mean True Positive Rate for " + str(self.iterations)  + " iterations is: \n" + str(meanTPR))

"""# Bulding Neural Network with Regularization Parameter"""

## Created a class for NEural network with Regularization parameter

class NN_reg:
  def __init__(self,X, Y, learningrate,n_input,n_hidden,n_output, iterations, lambd):
    self.input = X
    
    self.w_1 = np.random.normal(scale=0.5, size=(n_input,n_hidden)) #(2,2)
    self.w_2 = np.random.normal(scale=0.5,size=(n_hidden,n_output))
    
    self.Y = Y
    self.alpha = learningrate
    self.iterations =iterations
    self.N = Y.size
    self.lambd = lambd

  def forwardandbackprop_reg(self):

    results = pd.DataFrame(columns= ["MSE", "Accuracy", "TPR","FPR"])
    for itr in range(self.iterations):
  # feed forward
      hiddenlayer_input = np.dot(self.input,self.w_1)
      hiddenlayer_output = sigmoid_of(hiddenlayer_input)

      outputlayer_input = np.dot(hiddenlayer_output, self.w_2)
      outputlayer_output = sigmoid_of(outputlayer_input)




#backpropagation

      outputlayer_error = outputlayer_output- self.Y
      outputlayer_delta = outputlayer_error * outputlayer_output * (1-outputlayer_output)

      hiddenlayer_error = np.dot(outputlayer_delta,self.w_2.T)
      hiddenlayer_delta = hiddenlayer_error * hiddenlayer_output * (1-hiddenlayer_output)

      mse = mean_square_error(outputlayer_output,self.Y)

      acc = accuracy(outputlayer_output,self.Y)
      cp = correct_preds(outputlayer_output,self.Y)

      y_pr = outputlayer_output.argmax(axis=1)
      y_tr = self.Y.flatten()

      confm =  confusion_matrix(y_tr,y_pr, labels=[0, 1])
      TP = confm[0][0]
      FN = confm[0][1]
      FP = confm[1][0]
      TN = confm[1][1]
      tpr = TP/(TP+FN)
      fpr = FP/(FP+TN)

      results = results.append({"MSE": mse, "Accuracy" : acc, "TPR" : tpr, "FPR": fpr}, ignore_index=True)


# weights update
      
      m = self.input.shape[1]

      w_2_update = 1.0/m * (np.dot(hiddenlayer_output.T, outputlayer_delta)) + (self.lambd*self.w_2)/2 * m
      w_1_update = 1.0/m * (np.dot(self.input.T, hiddenlayer_delta)) + (self.lambd*self.w_2)/2 * m

      self.w_2 = self.w_2 - (self.alpha * w_2_update)
      self.w_1 = self.w_1 - (self.alpha * w_1_update)

      

    lst = []
    for i in range(self.iterations):
      lst.append(i+1)
    results['Iteration number'] = np.array(lst)
    columns_titles =['Iteration number', 'MSE','Accuracy','TPR', 'FPR']
    results = results.reindex(columns = columns_titles)
    print(results)
    fig, axes = plt.subplots(1,2, figsize =(15,5))

    ##Dataframe with MSE, Accuracy, TPR and FPR for every iteration
    results.MSE.plot(ax=axes[0],title="Mean Squared Error")
    results.Accuracy.plot(ax=axes[1],title="Accuracy")
    
    results.plot(x="FPR", y="TPR", ylabel = "TPR",kind="line",title ="ROC curve", color="r", legend=None)
    #sns.scatterplot(data = results, y = "MSE", x = "Iteration number")
    #sns.scatterplot(data = results, y = "Accuracy", x = "Iteration number")
    y_p = outputlayer_output.argmax(axis=1)
    y_t = self.Y.flatten()

    ## Printing the confusion matrix 
    cm = confusion_matrix(y_t,y_p, labels=[0, 1])
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=None)
    disp.plot()
    plt.show()

    # Printing the values of mean MSE, mean Accuracy and mean TPR
    meanMSE = results[['MSE']].mean()
    print("Mean Squared Error for " + str(self.iterations)  + " iterations with Regularization parameter is: \n" + str(meanMSE))
    Acscore= results[['Accuracy']].mean()
    print("Mean Accuracy for " + str(self.iterations)  + " iterations with Regularization parameter is: \n" + str(Acscore))

    meanTPR = results[['TPR']].mean()
    print("Mean True Positive Rate for " + str(self.iterations)  + " iterations is: \n" + str(meanTPR))

"""# Training the model

### Training without regularization parameter
"""

## Creating an object of class NN without reg parameter and training the model

Neu_1000 = NN(X_train,Y_train,0.001,2,2,2,5000)
Neu_1000.forwardandbackprop()

"""### Training with Regularization parameter"""

## Creating an object of class NN with reg parameter and training the model

Train_1000_reg = NN_reg(X_train,Y_train,0.001,2,2,2,5000,0.3)
Train_1000_reg.forwardandbackprop_reg()

"""# Testing the model

### Testing without regularization parameter
"""

## Creating an object of class NN without reg parameter and testing the model
Test_1000 = NN(X_test,Y_test,0.001,2,2,2,5000)
Test_1000.forwardandbackprop()

"""### Testing with regularization parameter"""

## Creating an object of class NN without reg parameter and testing the model

Test_1000_reg = NN_reg(X_test,Y_test,0.001,2,2,2,5000,0.3)
Test_1000_reg.forwardandbackprop_reg()

plt.close('all')

"""## Relationship of Accuracy with Regularization parameter, learning rate and number of Epochs"""

## Dataframe that shows the Training Accuracy, TPR and testing accuracy, TPR changes with the changing reg parameter and learning rate

Sta_df = pd.read_csv('/content/drive/MyDrive/ML Project/StatsHeartdisease.csv')
Sta_df

# An example of plot that shows the relationship between number of iteration and Training, test accuracy
fig, ax = plt.subplots()
ax= sns.lineplot(x='Epochs', y='Training Accuracy',color ='red', data=Sta_df, label='Training Accuracy', ci=None,markers='o')
ax1= sns.lineplot(x='Epochs', y= 'Testing Accuracy', color ='blue',data= Sta_df, label = 'Testing Accuracy', ci=None,markers='x')

plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0)
plt.ylabel('Accuracy')